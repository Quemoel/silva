{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação da estrutura de pastas e arquivos\n",
    "project_dir = 'meu_projeto'\n",
    "os.makedirs(project_dir, exist_ok=True)\n",
    "\n",
    "api_dir = os.path.join(project_dir, 'api')\n",
    "os.makedirs(api_dir, exist_ok=True)\n",
    "api_file = os.path.join(api_dir, 'app.py')\n",
    "\n",
    "data_dir = os.path.join(project_dir, 'data')\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "dataset_file = os.path.join(data_dir, 'dataset.csv')\n",
    "\n",
    "models_dir = os.path.join(project_dir, 'models')\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "model_rf_file = os.path.join(models_dir, 'random_forest_model.pkl')\n",
    "model_lr_file = os.path.join(models_dir, 'logistic_regression_model.pkl')\n",
    "\n",
    "docs_dir = os.path.join(project_dir, 'docs')\n",
    "os.makedirs(docs_dir, exist_ok=True)\n",
    "rf_docs_file = os.path.join(docs_dir, 'random_forest_model_documentation.md')\n",
    "lr_docs_file = os.path.join(docs_dir, 'logistic_regression_model_documentation.md')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geração do dataset de exemplo\n",
    "data = pd.DataFrame({\n",
    "    'feature1': [1, 2, 3, 4, 5],\n",
    "    'feature2': [6, 7, 8, 9, 10],\n",
    "    'target': [0, 1, 0, 1, 1]\n",
    "})\n",
    "\n",
    "# Salvando o dataset em um arquivo CSV\n",
    "data.to_csv(dataset_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão dos dados em features e target\n",
    "X = data[['feature1', 'feature2']]\n",
    "y = data['target']\n",
    "\n",
    "# Divisão dos dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento e ajuste do modelo Random Forest\n",
    "model_rf = RandomForestClassifier()\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "# Previsões com o modelo Random Forest\n",
    "y_pred_rf = model_rf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['meu_projeto\\\\models\\\\random_forest_model.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Avaliação da acurácia do modelo Random Forest\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "# Salvando o modelo Random Forest\n",
    "joblib.dump(model_rf, model_rf_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento e ajuste do modelo de Regressão Logística\n",
    "model_lr = LogisticRegression()\n",
    "model_lr.fit(X_train, y_train)\n",
    "\n",
    "# Previsões com o modelo de Regressão Logística\n",
    "y_pred_lr = model_lr.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['meu_projeto\\\\models\\\\logistic_regression_model.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Avaliação da acurácia do modelo de Regressão Logística\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "\n",
    "# Salvando o modelo de Regressão Logística\n",
    "joblib.dump(model_lr, model_lr_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a estrutura de dados com os modelos\n",
    "estrutura_modelos = {\n",
    "    'modelo_4': model_rf,\n",
    "    'modelo_5': model_lr\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentação dos modelos\n",
    "# Documentação do modelo Random Forest\n",
    "rf_documentation = \"\"\"\n",
    "# Random Forest Model\n",
    "\n",
    "Este modelo utiliza o algoritmo Random Forest para classificação.\n",
    "\n",
    "## Características utilizadas\n",
    "- Feature1\n",
    "- Feature2\n",
    "\n",
    "## Treinamento e ajuste do modelo\n",
    "O modelo foi treinado usando o conjunto de dados disponível no arquivo 'dataset.csv'. Foram utilizados 80% dos dados para treinamento e 20% para teste.\n",
    "\n",
    "## Métricas\n",
    "- Acurácia: {}\n",
    "\"\"\".format(accuracy_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentação do modelo de Regressão Logística\n",
    "lr_documentation = \"\"\"\n",
    "# Logistic Regression Model\n",
    "\n",
    "Este modelo utiliza o algoritmo de Regressão Logística para classificação.\n",
    "\n",
    "## Características utilizadas\n",
    "- Feature1\n",
    "- Feature2\n",
    "\n",
    "## Treinamento e ajuste do modelo\n",
    "O modelo foi treinado usando o conjunto de dados disponível no arquivo 'dataset.csv'. Foram utilizados 80% dos dados para treinamento e 20% para teste.\n",
    "\n",
    "## Métricas\n",
    "- Acurácia: {}\n",
    "\"\"\".format(accuracy_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Salvando a documentação dos modelos\n",
    "with open(rf_docs_file, 'w') as rf_docs:\n",
    "    rf_docs.write(rf_documentation)\n",
    "\n",
    "with open(lr_docs_file, 'w') as lr_docs:\n",
    "    lr_docs.write(lr_documentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [19/May/2023 19:08:58] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [19/May/2023 19:08:59] \"GET /favicon.ico HTTP/1.1\" 404 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Carregando os modelos treinados\n",
    "model_rf = joblib.load(model_rf_file)\n",
    "model_lr = joblib.load(model_lr_file)\n",
    "\n",
    "# Rota para previsões com o modelo Random Forest\n",
    "@app.route('/predict_rf', methods=['POST'])\n",
    "def predict_rf():\n",
    "    data = request.json\n",
    "    features = pd.DataFrame(data, index=[0])\n",
    "    prediction = model_rf.predict(features)\n",
    "    return jsonify({'prediction': prediction.tolist()})\n",
    "\n",
    "# Rota para previsões com o modelo de Regressão Logística\n",
    "@app.route('/predict_lr', methods=['POST'])\n",
    "def predict_lr():\n",
    "    data = request.json\n",
    "    features = pd.DataFrame(data, index=[0])\n",
    "    prediction = model_lr.predict(features)\n",
    "    return jsonify({'prediction': prediction.tolist()})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Flask in c:\\users\\nayan\\anaconda3\\lib\\site-packages (2.2.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in c:\\users\\nayan\\anaconda3\\lib\\site-packages (from Flask) (2.2.2)\n",
      "Requirement already satisfied: click>=8.0 in c:\\users\\nayan\\anaconda3\\lib\\site-packages (from Flask) (8.0.4)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in c:\\users\\nayan\\anaconda3\\lib\\site-packages (from Flask) (2.0.1)\n",
      "Requirement already satisfied: Jinja2>=3.0 in c:\\users\\nayan\\anaconda3\\lib\\site-packages (from Flask) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\nayan\\anaconda3\\lib\\site-packages (from click>=8.0->Flask) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nayan\\anaconda3\\lib\\site-packages (from Jinja2>=3.0->Flask) (2.1.1)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
